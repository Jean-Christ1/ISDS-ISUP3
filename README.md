# ISDS (ISUP et Sorbonne Universit√©)
Ing√©nierie, Statistique et Data Science (ISDS) du master Ing√©nieris Math√©matiques Appliqu√©es de Sorbonne Universit√© et d'ISUP.<br/>

üîó[https://isup.sorbonne-universite.fr/formations/filiere-ingenierie-statistique-et-data-science-isds] <br/>
üîó[https://sciences.sorbonne-universite.fr/formation-sciences/masters/master-mathematiques-et-applications/m2-parcours-ingenierie-mathematique]

<a id="top"></a>
<div class="list-group" id="list-tab" role="tablist">
<h3 class="list-group-item list-group-item-action active" data-toggle="list" role="tab" aria-controls="home">PROGRAMME ISDS 2 - ISUP3</h3>
  
* [1. BLOC base              : UE - Ing√©nierie 1 et UE - Math√©matiques et mod√©lisation](#2)
* [2. BLOC fondamental       : UE - Ing√©nierie 2 et UE - Informatique pour l'ing√©nierie](#2)
* [3. BLOC de sp√©cialisation : UE - Sp√©cialisation 1 et UE - Sp√©cialisation 2](#2)

  ---------------
  
  <a id="1"></a>
<font color="darkslateblue" size=+2.5><b>[1. BLOC 1 : UE - Ing√©nierie 1 et UE - Math√©matiques et mod√©lisation]()</b></font>

<a id="1.1"></a>
<font color="dimgrey" size=+2.0><b>[1.1 UE - Math√©matiques et mod√©lisation]()</b></font>
  

[**Machine Learning**]() (prof. Claire Boyer) : 
  
  Ce cours pr√©sente les grands principes de l‚Äôapprentissage statistique et automatique et les principales m√©thodes de pr√©diction (classification et r√©gression), de clustering et de r√©duction de dimension. On s‚Äôattachera √† aborder l‚Äôapprentissage automatique d‚Äôun point de vue th√©orique mais aussi d‚Äôun point de vue algorithmique, puisque la plupart des concepts pourront s‚Äôillustrer par des travaux pratiques en Python.  Il a pour but de fournir les outils n√©cessaires √† :
- Identidier les probl√®mes qui peuvent √™tre r√©solus par des approches de Machine Learning ;
- Formaliser ces probl√®mes en termes de Machine Learning ;
- IdentiÔ¨Åer les algorithmes les plus appropri√©s pour ces probl√®mes et les mettre en ≈ìuvre afin d‚Äôen comprendre les tenants et aboutissants ;
- Evaluer et comparer de la mani√®re la plus objective possible les performances de plusieurs algorithmes de Machine Learning et du Deep Learning pour une application particuli√®re.
  
- Principe de minimisation du risque empirique, th√©orie de Vapnik-Chervonenkis;
- Optimisation pour le machine learning;
- Apprentissage supervis√©: m√©thodes param√©triques, √† noyaux et non param√©triques;
- Apprentissage non-supervis√©: clustering et r√©duction de dimension;
- Compl√©tion de matrice;
- Introduction au deep learning (pour l'UE de Sp√©cialisation).

 
 [**Calcul stochastique**](https://www.lpsm.paris/pageperso/zhan) (Prof. Zhan Shi) :  
  
  L‚Äôobjet de la th√©orie des processus stochastiques est l‚Äô√©tude des ph√©nom√®nes al√©atoires d√©pendant du temps. Le but de ce cours est d'introduire les notions de martingales, de mouvement brownien et d'int√©grales stochastiques par rapport au mouvement brownien ainsi que les bases du calcul d'It√¥.
- Martingales √† temps discret, martingales √† temps continu, convergences et th√©or√®me d‚Äôarr√™t;
- Mouvement brownien, propri√©t√© de Markov et propri√©t√© de martingale; 
- Int√©grale stochastique par rapport au mouvement brownien, formule d‚ÄôIt√¥, th√©or√®me de Girsanov. 
- Introduction aux √©quations diff√©rentielles stochastiques, √©quations √† coefficients lipschitziens, diffusions et propri√©t√© de Markov.
 
<a id="1.2"></a>
<font color="dimgrey" size=+2.0><b>[1.2 UE - Ing√©nierie 1]()</b></font>
  
[**Mod√®les al√©atoires**] (Prof. Olivier Bardou):  <br/> 
  
  Ce module a pour objectif d'aborder la mod√©lisation Markovienne. Ces processus sont tr√®s int√©ressants dans la mesure o√π ils poss√®dent de nombreuses applications. La d√©couverte de ces processus de Markov comme nous le voyons sous-entend une compr√©hension math√©matique du ph√©nom√®ne mais aussi une approche pragmatique gr√¢ce √† des exercices appliqu√©s √† des situations quotidiennes.
- Cha√Ænes de Markov √† temps discret;
- Processus de sauts markoviens;
- Propri√©t√©s des processus en temps long, th√©or√®mes ergodiques.
- etc.

  
[**TP C/C++**]() (Prof. Vincent Lemaire) : 
  
  Ma√Ætriser les principes fondamentaux de la conception objet et les pratiquer de fa√ßon effective en C++ au travers d‚Äôune application r√©alis√©e de fa√ßon it√©rative. Mettre en ≈ìuvre les nouveaut√©s offertes par la derni√®re norme C++ 11 / 14. Les diff√©rents aspects abord√©s pendant ce cours sont les suivants :
- Syntaxe classique du C/C++;
- Programmation orient√©e objets (classes, h√©ritage, polymorphisme dynamique) ;
- Programmation g√©n√©rique (Template, STL, polymorphisme statique);
- la programmation moderne du C++14 et l‚Äôint√©gration avec R via Rcpp et Python via pybind11; 
- Exemples num√©riques li√©s aux √©quations paraboliques (m√©thodes d√©terministes et al√©atoires).
 

[**M√©thodes Num√©riques**]() (Prof. Cindy Guichard) : 
  
  Ce cours traite de la discr√©tisation des  √©quation aux d√©riv√©es partielles (EDP) en 1D (une dimension) et 2D notamment par la m√©thode des diff√©rences finies.

  
<a href="#top" class="btn btn-primary btn-sm" role="button" aria-pressed="true" style="color:white" data-toggle="popover">Retour au programme</a>
 ----------------------------------
  
  <a id="2"></a>
<font color="darkslateblue" size=+2.5><b>[2. BLOC fondamental : UE - Ing√©nierie 2 et UE - Informatique pour l'ing√©nierie]()</b></font>

<a id="2.1"></a>
<font color="dimgrey" size=+2.0><b>[2.1 UE - Ing√©nierie 2]()</b></font>  

[Mod√®les √† structures latente]()  (Prof. Jean-Patrick Baudry):  
  
  Ce module aborde l'ensemble des techniques d‚Äôexploration des donn√©es servant √† r√©sumer les informations sur les donn√©es ou √† d√©terminer des liens entre les points. Il a pour but principal de structurer les donn√©es en classes homog√®nes. C'est-√†-dire, regrouper les points (individus) en clusters ou classes de telles sortes que les donn√©es d‚Äôun cluster soient les plus similaires possibles. Ce cours, tout comme les cours cit√©s dans mes rapports pr√©c√©dant, y compris ce rapport et ceux √† venir, se veut pratique en proposant des exercices de TP par bin√¥me  et des application concr√®tes mis en ouvre principalement avec le logiciels R. Les notions abord√©es dans ce cours apportent des r√©ponses concr√®tes aux probl√©matiques li√©es :
- A la nature des observations (donn√©es) ;
- Au notion de similarit√© ou de dissimilarit√© entre observations ;
- Aux caract√©ristiques d‚Äôun cluster ;
- Au choix du nombre (optimal) de clusters et aux comparaisons de diÔ¨Ä√©rents r√©sultats de clustering ;
- au fonctionnement des algorithmes de clustering et au choix de ces algorithmes (ACP, Kmeans, CHA, Model-Based Clustering,  M√©thodes bay√©siennes, Markov chain Monte Carlo (MCMC methode)) ; 
- etc.
  
  
[**Robustesse et mod√®les**] (Prof. Michel Broniatowski) :  
  
La robustesse implique une insensibilit√© aux √©carts d√ªs √† une non-conformit√© aux hypoth√®ses sous-jacentes √† un mod√®le probabiliste. Autrement dit, la robustesse est la capacit√© √† g√©n√©raliser les conclusions d'une analyse statistique et pr√©dictive :  c'est le principe de ce cours. Et les notions vues dans ce cours sont les suivantes :
- Mod√®les param√©triques et semi param√©triques ;
- Crit√®res statistiques, vraisemblance et divergences, risques empiriques ;
- Vraisemblance empirique et m√©thodes associ√©es ;
- S√©lection de mod√®les (cadre bay√©sien, cadre inf√©rentiel) ;
- Inf√©rence robuste , fonctionnelles statistiques, diff√©rentiabiit√© des fonctionnelles ;
- fonctions d‚Äôinfluence, sensibilit√© et outliers. M-estimateurs, L-estimateurs ;
- etc.
  
<a id="2.2"></a>
<font color="dimgrey" size=+2.0><b>[2.2 UE - Informatique pour l'ing√©nierie]()</b></font>  
  
[**S√©ries chronologiques**] (Prof. Jean-Patrick Baudry) : 
  
Le principe de ce cours est d'apprendre √† mod√©liser et √† manipuler des donn√©es dont la structure est d√©termin√©e par les corr√©lations au cours du temps, et d‚Äôen tirer des cons√©quences pour des prises de d√©cision. Et l‚Äôun des objectifs principaux de l‚Äô√©tude des s√©ries chronologiques est la pr√©vision des valeurs futures de ces s√©ries. Les points abord√©s sont :
- Vecteurs al√©atoires du second ordre et vecteurs gaussiens;
- Pr√©vision lin√©aire; 
- Mod√®le de Kalman et filtrage; 
- S√©ries temporelles et mod√®le ARMA.
  
  
[**Contr√¥le qualit√©**] (Prof.  Mitra Fouladirad) :  
  
  les objectifs de ce cours sont les suivants :
- Comprendre les √©v√©nements et trouver les causes de la variabilit√© dans un proc√©d√© ;
- Expliquer les bases de la carte de contr√¥le Shewhart, en expliquant le choix de la taille de l‚Äô√©chantillon, les limites de contr√¥le, les intervalles d‚Äô√©chantillonnage ;
- Expliquer le concept des sous-groupes ;
- Comprendre les sept bases de Contr√¥le Statistique des proc√©d√©s (CSP) ;
- Expliquer les deux phases de carte de contr√¥le ;
- Expliquer l‚Äôutilisation de la dur√©e moyenne de d√©tection pour une carte de contr√¥le ;
- Analyse graphique de la carte de contr√¥le.
 

[**Programmation en Python**] (Prof. Pascal Hav√©) :  
  
  Ce cours aborde les concepts courants de la programmation en Python; la programmation orient√©e objet en Python; manipulation des principales librairies Python (tableaux avec Numpy, jeu de donn√©es gr√¢ce √† Pandas, etc.). Son but est de conduire √† une bonne ma√Ætrise des bases des outils python permettant de manipuler et repr√©senter les donn√©es, etc.
 

[Introduction au CUDA (GPU)] (Prof. Roman Lakymchuk et Bouazza Saadeddine) : 
  
  Ce cours introduit de fa√ßon simple et efficace √† la simulation sur GPU (Graphics Processing Units). Il est agenc√© autour de la simulation Monte Carlo fortement adapt√©e √† la parall√©lisation. Il permet ainsi de se concentrer sur les optimisations permises par l‚Äôarchitecture du GPU.
 
  
  
  
  
  
  
  
  
  
  
  
  
